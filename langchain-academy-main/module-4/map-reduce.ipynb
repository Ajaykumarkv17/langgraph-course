{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd4f701",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/map-reduce.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239947-lesson-3-map-reduce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36737349-c949-4d64-9aa3-3767cbd02ad1",
   "metadata": {},
   "source": [
    "# Map-reduce\n",
    "\n",
    "## Review\n",
    "\n",
    "We're building up to a multi-agent research assistant that ties together all of the modules from this course.\n",
    "\n",
    "To build this multi-agent assistant, we've been introducing a few LangGraph controllability topics.\n",
    "\n",
    "We just covered parallelization and sub-graphs.\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, we're going to cover [map reduce](https://langchain-ai.github.io/langgraph/how-tos/map-reduce/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24e95c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain_openai langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff57cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcd868a",
   "metadata": {},
   "source": [
    "We'll use [LangSmith](https://docs.smith.langchain.com/) for [tracing](https://docs.smith.langchain.com/concepts/tracing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fdc647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbe9b9f-4375-4bca-8e32-7d57cb861469",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "Map-reduce operations are essential for efficient task decomposition and parallel processing. \n",
    "\n",
    "It has two phases:\n",
    "\n",
    "(1) `Map` - Break a task into smaller sub-tasks, processing each sub-task in parallel.\n",
    "\n",
    "(2) `Reduce` - Aggregate the results across all of the completed, parallelized sub-tasks.\n",
    "\n",
    "Let's design a system that will do two things:\n",
    "\n",
    "(1) `Map` - Create a set of jokes about a topic.\n",
    "\n",
    "(2) `Reduce` - Pick the best joke from the list.\n",
    "\n",
    "We'll use an LLM to do the job generation and selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "994cf903-1ed6-4ae2-b32a-7891a2808f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Prompts we will use\n",
    "subjects_prompt = \"\"\"for a given {topic} classify this into 3 subjects\"\"\"\n",
    "fact_prompt = \"\"\"Generate a intresting fact about {subject}\"\"\"\n",
    "best_fact_prompt = \"\"\"Below are a bunch of facts about {topic}. Select the best one! Return the ID of the best one, starting 0 as the ID for the first fact. Facts: \\n\\n  {facts}\"\"\"\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0,api_key=os.getenv(\"GITHUB_TOKEN\"),base_url=\"https://models.inference.ai.azure.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b883cc-3469-4e96-b1a4-deadf7bf3ce5",
   "metadata": {},
   "source": [
    "## State\n",
    "\n",
    "### Parallelizing joke generation\n",
    "\n",
    "First, let's define the entry point of the graph that will:\n",
    "\n",
    "* Take a user input topic\n",
    "* Produce a list of joke topics from it\n",
    "* Send each joke topic to our above joke generation node\n",
    "\n",
    "Our state has a `jokes` key, which will accumulate jokes from parallelized joke generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "099218ca-ee78-4291-95a1-87ee61382e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Subjects(BaseModel):\n",
    "    subjects: list[str]\n",
    "\n",
    "class BestFact(BaseModel):\n",
    "    id: int\n",
    "    \n",
    "class OverallState(TypedDict):\n",
    "    topic: str\n",
    "    subjects: list\n",
    "    facts: Annotated[list, operator.add]\n",
    "    best_selected_fact: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7176d1c-4a88-4b0f-a960-ee04a45279bd",
   "metadata": {},
   "source": [
    "Generate subjects for jokes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "45010efd-ad31-4daa-b77e-aaec79ef0309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topics(state: OverallState):\n",
    "    prompt = subjects_prompt.format(topic=state[\"topic\"])\n",
    "    response = model.with_structured_output(Subjects).invoke(prompt)\n",
    "    print(response)\n",
    "    return {\"subjects\": response.subjects}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5296bb0-c163-4e5c-8181-1e305b37442a",
   "metadata": {},
   "source": [
    "Here is the magic: we use the [Send](https://langchain-ai.github.io/langgraph/concepts/low_level/#send) to create a joke for each subject.\n",
    "\n",
    "This is very useful! It can automatically parallelize joke generation for any number of subjects.\n",
    "\n",
    "* `generate_joke`: the name of the node in the graph\n",
    "* `{\"subject\": s`}: the state to send\n",
    "\n",
    "`Send` allow you to pass any state that you want to `generate_joke`! It does not have to align with `OverallState`.\n",
    "\n",
    "In this case, `generate_joke` is using its own internal state, and we can popular this via `Send`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bc83e575-11f6-41a9-990a-adb571bcda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.constants import Send\n",
    "def continue_to_facts(state: OverallState):\n",
    "    return [Send(\"generate_fact\", {\"subject\": s}) for s in state[\"subjects\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9847192d-d358-411e-90c0-f06be0738717",
   "metadata": {},
   "source": [
    "### Joke generation (map)\n",
    "\n",
    "Now, we just define a node that will create our jokes, `generate_joke`!\n",
    "\n",
    "We write them back out to `jokes` in `OverallState`! \n",
    "\n",
    "This key has a reducer that will combine lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bcddc567-73d3-4fb3-bfc5-1bea538f2aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactState(TypedDict):\n",
    "    subject: str\n",
    "\n",
    "class Fact(BaseModel):\n",
    "    fact: str\n",
    "\n",
    "def generate_fact(state: FactState):\n",
    "    print(state[\"subject\"])\n",
    "    prompt = fact_prompt.format(subject=state[\"subject\"])\n",
    "    response = model.with_structured_output(Fact).invoke(prompt)\n",
    "    return {\"facts\": [response.fact]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02960657-d174-4076-99a8-b3f9eea015f4",
   "metadata": {},
   "source": [
    "### Best joke selection (reduce)\n",
    "\n",
    "Now, we add logic to pick the best joke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8d672870-75e3-4307-bda0-c41a86cbbaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_fact(state: OverallState):\n",
    "    facts = \"\\n\\n\".join(state[\"facts\"])\n",
    "    prompt = best_fact_prompt.format(topic=state[\"topic\"], facts=facts)\n",
    "    response = model.with_structured_output(BestFact).invoke(prompt)\n",
    "    return {\"best_selected_fact\": state[\"facts\"][response.id]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837cd12e-5bff-426e-97f4-c774df998cfb",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2ae6be4b-144e-483c-88ad-ce86d6477a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKEAAAGwCAIAAABOzpJrAAAAAXNSR0IArs4c6QAAIABJREFUeJztnWlcE1e/gM9k30PYCQFlFRQUFFzAXbCCqKDWFS1atb4q6mu10tar1lZra11arWJdW7VSrVoFF7RSXHHfQJFdZIckQAjZl/thvFyqgKDJTJiZ54M/M5mc808e5pw5Z84CGY1GQIBpSGgHQGB2CMfYh3CMfQjH2IdwjH0Ix9iHgnYAr6OU66SVWkWDTiHT63VGna4TNO0gCFBoEJtLYfHIPBsqz5qKdkT/ArKQ9nG9VFvwSF6Y2ahVG+gsEotLYfHIHD5Fp7GI8NoGIgN1o6GxQaeQ6SEIqBUGN3+2R0+2jRMd7dCARTjWqAw3U8QNtTprB5q7P9vJjYluPO9PdamqKLOxTqyFAAgZY8uxQrmwRNnx42t1t85KQqJs/QfyUQzDTOTcb7iZLPYP5QeFW6MYBpqOLx6utHGk9QlD8/sjwNOM+vxH8nH/cUYrANTuq0/vKuviw8a8YABAjwH8wOGCff9ThFYA6FzHf2wu6RNm5dmLi3zWaCGpUP+1s/zjr92QzxoFx38frXJ2Z/r24yGcL+q8zFE8TKtFvtBG2nFWRr2qUR+EgyK6RZ7eqlfI9MEjEf36SNfH6cdqcCsYANCjPz/rZr28Todkpog6vpksHhBlg2SOFkjIGNubyWIkc0TOsapRJy7X9BkhQCxHy6RbH64RAEmFGrEckXNcmKVg88iIZVdRUVFeXv7OH8/KylKrzaXBypZa8KTRTIm/CYKOM+Xu/hxk8iotLR07duyzZ8/e7ePJyclxcXFKpdLUcb3CzZ9dlIk5xwaDUV6nc/NjI5OdTqd7t/YC/CnzXcEw9iIGjQU1SLVmzaUJhLrLZRKtVm2WRppKpdq4cePVq1cBAIGBgcuXLzcajRMnTgQAJCQkAACioqLWrl1bVVW1c+fOGzduyOXyLl26zJo1a9SoUXAKkyZN8vDw8PDwSEpKUqlUS5Ys+e677wAAYWFhAIA1a9aMGTPG9HEboXqJlovIU0iEHCtkepZ5KuMDBw6kpKTMnz/f1tY2JSWFyWSyWKxvvvlm1apV8+fPDwoKsra2hq/sp0+fTpw40crKKi0tbdWqVS4uLj169IATycjIUKlUW7duVSgUXl5eZWVlhw8f3rZtG4fDcXV1NUfYbB65UaY3R8pvgpTjBj2LaxbH5eXlTCYzLi6OQqFER0fDB318fAAAXbt2DQgIgI84OzsfP34cgiAAwLhx48LCwtLT05scUyiUDRs2MJmvHmuKRCIAgJ+fn5WVlTliBgCw+ZTGeoRaycjVxzSmWfKKiIhQqVTx8fH5+fltn5mbm7ts2bJRo0bFxMTo9XqJRNL0lp+fX5NgZKDSIcTyQsgxi0uWic3yZxsSEvLjjz9KJJIpU6Z88803Ol3Ludy9e/ejjz7SaDRr1qz5/vvv+Xy+wWBoehdhwQAAmUTH5CDUkkSorGZxKYoGcxVNISEh/fv3P3r06NatW52cnD7++OM3z9m7d69IJNq2bRuFQmmnVLP25DfKdGweQj8+Qtcxx4pipiEvGo0GAEAikaZPn25nZ/f8+XMAAIPBAADU1NQ0nVZXV+ft7Q0L1mg0CoWi+XX8GvBfQPOPmxw6k8QRIOQYoWxoDJJBB8rylc6eJi4Vk5KSrly5EhkZWVNTU1NT0717dwCAg4ODs7Pz4cOHmUxmfX39lClTgoKCkpOTT58+zefzjxw5IpPJCgoKjEYjfBf2Gr169SKTyT/88MPYsWPVavWECRNMG3NdjaamVGPtQDNtsq1BXrt2LTI5qZWGqmJVF18Td4NIJJL79++fP3++sLBw7Nixn3zyCYlEgiCoZ8+eN2/eTE1NLS8vHzZsWGhoaGFhYVJS0r1798LDwydPnpyamurj4wPfb1tbW8OtYRgej+fg4HDp0qVr167JZLKoqCjTxpx9R8bmU1x9WKZNtjWQe35cL9ZcPy0e/bEQmewsmb+PVnXvxxO6I3Sjh9ywUL4tjc4kZ9+R+fZteQSIwWAYPnx4i28JBILa2to3jw8ZMuSrr74ydaSvs2PHjj///PPN43Q6vcVeT3t7+2PHjrWWWkmuQl6rQ0ww0uNAFA26o9+XtDGmqbUnRVqtlkptoduPyWQKBGZ/WFlfX9/Y2MIjBI1GQ6O1UKeSyWQHB4fWUvtjc8mwSXb2LgxTh9kqSI/1uXtRyuaRu/fH4Gjq9lD0tLEkVzE4xg7JTJEe6xM80jr7bkN5gbke21kyMon26skahAWjM756QrwoZW+FSoHomCZL4Oj3L6d+ZpYnHG2Dzvhqvd7461cvxnwitHO2iFlf5qZRpvt948u4tV2pNBQuKjTnwiRtehk0UoD5kfSleYqLh6qmfuaKWAf1a6A8p+36XzWVL9QDxtg4e3T66YpvIi5T30gW86wpwya1epuNAOjPTa14ocxIllg70Ry7Mtz9ODRGp1/aQK8zFmU1Vr9UFecoQsfYItaf1RroO4Z5+VyRc6+hMEvu4s1i8ylsHpnNo7B4ZD1CYyXeCwiC1Apdo0zfWK/TqA259xvc/NjevbkePREao9g2luK4ibJ8haRC0yjTN8p0EAAqRatPh96NR48e+fn5wQ+gTAWZCpHJEJtHZvMpAjuqq6n75N8Ti3NsboYOHZqcnMzlYvxGrzmdvvIjeCuEY+yDO8e+vr4tjgvAMLhznJ2djbdbENw5RuBZpKWBO8ctjjXANrhz7OyM2hpKaIE7x2VlZWiHgDS4c+zv7492CEiDO8eZmZloh4A0uHOMQ3Dn2NbWlmgfYxyxWEz0c2Ece3t7tENAGtw5rq6uRjsEpMGdYxyCO8deXl5oh4A0uHOcl5eHdghIgzvHOAR3jpvWa8IPuHP89OlTtENAGtw5xiG4c0w8d8I+xHMnAgyCO8fE2FvsQ4y9JcAguHNMjK/GPsT4auzj7e2NdghIgzvHubm5aIeANLhzjENw59jJyQntEJAGd44rKirQDgFpcOfYz88P7RCQBneOs7Ky0A4BaXDn2M/Pj+jLxDhZWVnEMwmMY6b9Ey0ZvKzBFhERAe9WUFNTY21tTSaT9Xq9o6Pjvn370A7N7CC3Zwi6kEikps0qqqqqAAAsFmv58uVox4UEeCmrAwICXiux3N3dhw0bhl5EyIEXx1OmTGnew8VkMmfOnIlqRMiBF8f+/v5NrSaj0ejl5dXaXlLYAy+OAQCxsbFCoRCuiWfMmIF2OMiBI8d+fn5wR6aXlxdOamKYt99Xa9UGSYVGIe8MC8K/jVGDPyrN1Y4Ln1iY1cK+a50OBotkK6S/dXeGt7SPr56syX8kZ/MpTA5eWlmdi4pChXtPTvj0tvYkacvx+QMVAidGjwG4G+TWuSh8Ist7KItZ6Ewmt9xH26rjS0eqrBzoPsFWZo6QwASU5Tdm36qLWdjyUqAtF+VVJSqV0kAI7iw4e7I5VtSiVm4yWnYsrdBQqDi65cYAdBa5pqyFzZhbddwo01nZtrCzL4HFYmVPU8pb3iepZccGPdDrcPE8CjMYdECrarl9SxTI2IdwjH0Ix9iHcIx9CMfYh3CMfQjH2IdwjH0Ix9iHcIx9CMfYB8uO9Xp9Zuaj90+nsrKiorL8PRPR6XSxM2N2JW57/3g6CpYdb9r89ZZtG94zkbLy0mmxY3Nynr1nOhAEcbk8BoPxnum8A+YapVVa+lIkMvvsMaPR2MYkRI265eepHUKv05lkShiZTN7186/vn8470PJYnzupUo0K9Bpq3f6EJBLx9h2b7t+/TaFS+/Tpd/Xq5d27Dru5eQAATp/589jxw2JxtaOjcMTwUZMnzaDT6Xn5OfGLZ2/c8NMve7cXFOQ6ODh9MndxaOgQOLWKyvKdO7fcf3CbRqN7e/nMnr3Ap1t3AMCPP3135erl5ctW7UzcWlZW8sOmnS6iLvsO7Lx9+0Zjo9zFpcu0qbPCRowCAGz8fm1qakpTeL8fOePkKAQAPHx0b8/eHQUFuQKBdWBA8JyPF9rY2Lb2pSoqy6dNH9v08oMPohI+Wwt/2V2JW2/fuaHT6fz9AuZ/stTd3RMAsGr1py+KCry8fO7dvwVBpH79QhfM/69AYN2UTuz02R/PXgAAUKlUhw7v/eefizXiagcHp5Hho6dPm6XVarf9tPHmzasAgJ49AxctWO7o2N7VSwoeNYhLFWEtDd4zzXWs1+u/+HKptFayZEmCVCres3dHYEAQLPjgr78c//Pw+JgpXbq4l5S8+OPYb6VlL79IWAcAUKvVX32dEL9ohZOj8MDBxG82fJn0ewqfbyWRiOMXz3Z2dlm0cDkEQRcvnl2ydE7izkNwgo2N8n0Hdi5dkqBSKXsHBldUlj9//nTc2Il8ntXV62nrN6xydnbx9ekRO212TXVVRUXZ5wnrAAA21rYAgPsP7iR8vjg8LDImenKDrP7EyaPLls/fvetwa0WojbXtl198s37Dqllx8wMDggQCa1jPsuXzZbL6eXMXM+iMo3/8umz5/EO/neJyuACAGnH12LETJ02akZubvW//zhdFBbt2/iawsv563Q9frUto/nNlZj0aHzPF08P7RXFhSWkxmUz+9bdfUlNTZsXNt7GxTb2YwmQyTWLHNI6zs7Ny856vWb1x6JAwAMDLly/OXzij0Whksvojv+9f9eX6IYNHwGfa2Nht3fbtooWvJgzGL1oxfNhIAMCcOYs+mR/7+MmDwYOGHzq8V2BlvXnTLgqFAgAID4uMnRmdcu5U/MLlAACNRrN82Spf31fLegidnA/uPw6X2BER42ImhN24ke7r00MkcuXzraS1En//gKY4t+/YNCZq/OL4z+CXQUH9P5o18e69jEEDWx5ST6PRvL18AACurl2b0rn097mXL19s/mFX78BgAIC/f+C02LEnTyZ9NHMuAKBrF/dJH8YCAHx9erDZnPUbVt25czMkZPDA0KFN1cqVq5cfPrq3Yvn/REaMa55dRWU5k8mcNjWOQqGMjow2iRqTOa6uqQIACIUi+KVI5GowGJRKxf37t3U63foNq9ZvWAW/BVcN4ppXm6UxGa/+VB0cnAAAYnENAOD27RvVNVWRUYOa0tdqtTXVVfD/GQxGk2CY/ILcg7/uhm+L9Hq9VCppMcjKyori4qKyspKUs6f+Ffz/pdxOHj++z2FzYMEAAEdHJ1fXrjm5LdyU9e0bAgDIfp4VEjK4+fE7d2/S6fQPRka9dn7YiIjLly+sTIhfuOBTuPA3CaZx7OzsAgDIzHwE/9VnZ2fZ2trx+VYSqRgAsGH9Nnu7f9UTQqGo6EVB8yNUChUAYDDoAQDSWsmAAYPmzYlvfgKbzYH/w2Symh9/8PDuyoT4wICgz1asYbPYq9euMBhbHtZUWysBAHw0c97gQf+azWZt3Wp93CLyRjnf6l9jznk8vkRc8+aZHDYHgiCFUvF6JFKJrY0dmUx+7Xi/viHfbvgxcfe2j+dOGR0ZvXRJAlySvSemcdzN2zc4qP8ve36qqqqoq6+9cfPKqi/XAwC4XB58gqtr1/anxuXy6uvr2vmRQ4f2CoWiDeu3wT9HU8EA0/yOksPhAgDUalWHgnkTO1v7Z8/+tWGBVCpxsHd880yxuMZoNL729w1HIq1tubDp1zckOKj/iZNHd+7a6uDgNCP24/cJFcZk7eP4RStEIteS0mIrvmDH9gNwxRwYGAxB0Km//mg6TalUvjWp3r37ZmU9zsnNbs+n6mV1nh7esGCNRqNQKgyGV9cxg8GUSiVNL0UiVwcHx/MXzjSlptPptFpt28HQ6QwAQPPLtEePng0NsuzsV2tAFRTklZWVNK/1mzh3/jQAoEf3nq8dDwwMViqVl9NSm47odDo4fnjJgw8nTre1tcvLe952bO3ENNexTqdbsOijDyfGOju7QBDU0CCTy+UcDkfk7DI+ZsqJk0e/WPXfgaFDJRLxX6ePfbvhR7hIb42PZs67dev6is8WTvowViCwvnPnpt6g/2bd5hZPDggISk1NPnf+NI/LP37iSEOD7EVRAdxu7tWz9/kLZ7Zs3eDvF8Dl8kJCBi9c8OnqNSsWxseNHTPRoNenXkwJD4+cOGFaG8HY2zsInZyP/XmYwWTKZPXjY6aEjYg48vuBtetWzoidQyKRDh3aa2UlGDf2Q/j8ohcFe/buEIlcs7Ienzt/ul+/UD+/Xq+lGR4W+dfpYxu/W/P8+VNPD+/Covz7D27/knjk5KmkGzevhIdFSiQ1YnFNt27dO66iBUzjmEKhBPXpf+jwXvjvEQDA5XB/+nFf167uCxcss7d3OHXqj7t3M2xsbAcNHGZn+5YdiJ2Foh0/7d+1e9uR3/dDEOTl5RMTPbm1k2fH/UcqEW/fsYnL5UWNHj9pYuyWbRsePrrXOzA4PDwyJ/fZxUtnM25dG/XBmJCQwYMGDvt2/bYDBxN/3rmZzeb09A/s2bN328FAELRq1YbvN3214+cf7O0dhw0d6ejotOm7n3fu2rIrcavBYOjpH7hwwadwswoAIBBYZ2dnnfrrDzqdMXbMhLn/vquAodPpm39I3LNn+6W/z6WcPenoKBw2dKROpxMKRVqNZlfiVjabM378lMmTTDNJ2mR9IHq9Hr6JMBqN5RVlc+ZOmfRh7Ky4+SaJsrOwavWnNdVVuxMPI5+12ftA1Gr1gkUf2ds79urZm0qlZWY+VKlUHh6dYzVwuVw+dfrrzRiYT+YtiRodg3hEJsY0jiEIGhk+Oi0t9cDBRBqN5ubmuWb1xteaKBYLi8X6ZffvLb7F4/IRD8f0mKysJkCXNspqLD9bJIAhHGMfwjH2IRxjH8Ix9iEcYx/CMfYhHGMfwjH2IRxjn5b7qxksskHf8ogZAssEIgE2v2WbLV/HfFtKxYu3D9ggsByqipUcQUcci7xYGiUWFjPGD4312i6+rBbfatkxmQL1G2V98bcyMwdGYBrSj1V49+byrKktvtvW2sZlBcrU3yoDhlhbOdBZXGL9aotDo9TXlKly79f3GWHt3ZvT2mlvWaNcXqd7kFZb+UKlaMBI0a1Wq+k0GsDEdnx8GyrPltpzIM9O1NZ0SLzs09bE0KFDk5OTuVwu2oEgB+7axwkJCahMAkYR3F3HOAR31/HPP/+sUqnQjgJRcOf4+PHjb53/gjFwV1bn5OR4enq+OWcQw+DOMQ7BXVm9fv16oj7GOJcuXSLqY4xz//79Xr16mWR+fmcBd45xCO7K6s8//7w9axlgCdw5zsjIaJoIjxNwV1Zfv369f//+RH1MgClwV1YvX76cqI8xzr1794j6GOMQ7WMCDIK7snrlypVEfYxxbt++TdTHGOfKlSuhoaFEfUyAKXBXVicmJhLPjzFOUlIS3p4f487xnDlz6HQ62lEgClEfYx/cXcdnzpwhymqMs2XLFuKeC+OMGjWKSm15ni5WIepj7IO765ioj7EPUR9jn3nz5hHtYwKsgbvrODExUW2Kva87EbhznJSUBG95hx9w55iojwkwCO6u4z179hD1McY5cuQI3upjvJTVkydPplKpEARJJBI+n08mkyEIYrPZiYmJaIdmdvAydC0vL49EelVoVVdXw1tJf/rpp2jHhQR4KauDg4NfO+Li4jJ5cqvbKmMJvDieMWMGn///m6CSSCScCMaR44EDB3p4eDS9dHV1nTRpEqoRIQdeHDe/lOl0emxsLNrhIAeOHA8aNMjT0xMAIBQKo6Oj0Q4HOd79vtpoMMrrdJ1rse8pE2eVFIknT4hrqO1kU55YXDKZ8o4/9bu0j4uyGh9frSvNV9o40dUKjKxPb+GoFHorO2qvwVa+fXkd/WyHHT+7I8u5Kw+OsOXb0DqaGcH70CDVPk6X2DrTgkdad+iDHXP8NENWmCkfOlnY8QgJTMOts9U8a0q/UR3Q3IF7Lo3akPuwgRCMLv1H24vL1LXVHehy74BjSblaq8JF57bFA9WUduDRWQccy6Q6x67Md4qJwJTYuzI61C7oQNtJrzUqG4m7aPTRqIxkcgd2PMVRHwhuIRxjH8Ix9iEcYx/CMfYhHGMfwjH2IRxjH8Ix9iEcYx/CMfbBo+Nn2VnvP+XJYDDs279z4qRRY6OH37p1/R1S0Ov1mZmP3jOM9oA7xxdSkxcuilOp3neZ8pSzp44m/Tp50owvEtb5+QW8QwqbNn+9ZduG9wyjPSA6F6a09KVI5GruXIxGI9T6SEJTTVq8c/dm78DgDydOf+cUNEhNnzSvY4lEvH3Hpvv3b1Oo1D59+l29enn3rsNubh4AgIeP7u3Zu6OgIFcgsA4MCJ7z8UIbG9u8/Jz4xbM3bvjpl73bCwpyHRycPpm7ODR0CJxaRWX5zp1b7j+4TaPRvb18Zs9e4NOtOwDgx5++u3L18vJlq3Ymbi0rK/lh004XUZd9B3bevn2jsVHu4tJl2tRZYSNGwRfxth83AgCix4cBAFZ+tmbUB2NaC6aN7zUivK/BYAAADBsRFL9oxfiYyZmZjw4d3puZ9QgA4NOtx/z5S7t5+8Inq1SqQ4f3/vPPxRpxtYOD08jw0dOnzdq0+et/0i/BKQAAfj9yxsnRXANszOhYr9d/8eVSaa1kyZIEqVS8Z++OwIAgWPD9B3cSPl8cHhYZEz25QVZ/4uTRZcvn7951GL7Ovvo6IX7RCidH4YGDid9s+DLp9xQ+30oiEccvnu3s7LJo4XIIgi5ePLtk6ZzEnYfgBBsb5fsO7Fy6JEGlUvYODK6oLH/+/Om4sRP5PKur19PWb1jl7Ozi69OjX9/QSR/GHjt++Nv129hsDlyotBYMg8Fo7autW7vpl73b6TT6zJlz3d29AACVleVqjXpG7BwSiXT69PGEzxcfPZLMYDDgHyEz69H4mCmeHt4vigtLSovJZHLstNk11VUVFWWfJ6wDANhYt/Un9Z6Y0XFefk5u3vM1qzcOHRIGAHj58sX5C2c0Gg2NRtu+Y9OYqPGL4z+DzwwK6v/RrIl372U4OgoBAPGLVgwfNhIAMGfOok/mxz5+8mDwoOGHDu8VWFlv3rQL3iYgPCwydmZ0yrlT8QuXAwA0Gs3yZat8ff3gBIVOzgf3H4dL7IiIcTETwm7cSPf16SEQWAuFIgCAr68fn28Fn9xaMIMGDmvtq4WGDkk69huTwRwYOhQ+EhYWER4eCf+/W7fuyz6dn5n1KDio/5Wrlx8+urdi+f9ERoxrnoJI5MrnW0lrJf7+71KXdwgzOpZKxAAA+DeFv5XBYFAqFVKppLi4qKysJOXsqebnV1dXwY6ZjFcjihwcnAAAYnENAOD27RvVNVWRUYOaztdqtTXVVfD/GQxGk2CY/ILcg7/uzsl5BpcoUqmkxSArKytaC6ZDXxaCoGvX/zl2/HBxcRGLxQIA1EolcLVNp9M/GBnVodRMixkdw8IyMx95e/kAALKzs2xt7fh8q/LyUgDARzPnDR40vPn51ta2FZVlzY9QKVQAgMGgBwBIayUDBgyaNye++QlsNgf+D5PJan78wcO7KxPiAwOCPluxhs1ir167wmBseXBMba2ktWA69GV/O7T3wMHECeOnzpsTL5GKv1qXAOdYK5XY2tiRyeQOpWZazOjY3d0zOKj/L3t+qqqqqKuvvXHzyqov1wMAOBwuAECtVrm6dm1/alwur76+rp0fOXRor1Ao2rB+G1ywNxUMTTSNKn+3YF5DrVb/fvTA6MjoRQs/fa0M4HC40tqWi5DmYZgV87aP4xetEIlcS0qLrfiCHdsPwBWzSOTq4OB4/sKZpr20dDrdW9cp7d27b1bW45zc7KYjbWzFVS+r8/TwhgVrNBqFUgHfBjf5hsv/dw7mNVQqpVqt9v6/G+l6WR3cSQIACAwMViqVl9NSm05u2l2KwWBKpZKmwMwHee3ate08taZULZPqXLqx23m+TqebGTc+MiI6oFcfOzt7AACfZ0Wj0SAIcnBwOnfu9M2Mq0YjePYs86ft32t12u7d/aVSSXLKyRHDR7m4dIFr3N+PHugbPKB7d393d69Lf5+7dOmcXq8vKS0+cmT/lWuXhw/7AK6qi4uLJk+a0ZR18csXV678LRBYV1VVbvtpY1lZCQRAVNR4CIIYTNbpM8dfFBdCAHqWnenTrXtrwbT97c5fOEOlUOH7LAaDce162rNnmba29tnZWdt+3KhQNDo6CPv2DenSxT3j1rWzZ081NMhqpZJLf5/bs3d71OjxEATJ5Q1p/6RKJDUNDbLq6kr4K7eHqmIViWQUebHacS4wr2MSiZSX9zzl7Mn0K39fvXr50t/nUlJODBgw2MpK0MXVzadb9ydPHl68dDb7eZaHu1d4+GgbG9s2HPO4vNCQIcUviy5dOnv3XgabzRkdGd21q3uLjnt071VcXHjyVNKjx/eGDgkfHz057Z9ULy8fJydnHpdnZ+eQnn4pI+NaQ4Psgw+iWgum7W/X3DEAoFfP3rdv3/jr9LGS0uK5c+NdXLokJ5/4cOJ0Go02ZEh4fX1d+pVLN26m18vqhg4J797dn0wmu7t7NjTUX0678PjJAz7fqk/vvu38YTvquAPznZ7dkpXkqULG2rfzfPiGFr7dMBqN5RVlc+ZOmfRh7Ky4+e1PgeBNnlytJZMN/SNt2nm+Ge+5NBrNfxbOtLd37NWzN5VKy8x8qFKpPDy8zZejCZHL5VOnt9zg+WTekqjRMYhH9O6Y0TEEQSPDR6elpR44mEij0dzcPNes3vhaE8ViYbFYv+z+vcW3eFx+i8ctFjM6plKpkyfNaF5NdiJIJJL5OpARBnfPFnEI4Rj7EI6xD+EY+xCOsQ/hGPsQjrEP4Rj7EI6xD+EY+3SgL5NCAUwOmmNWCGCoDIjakcFDHbiO+Xa08gLFO0VFYEqqXii5Nh24ODvg2E5EozGIsh19IAAcXDuw1VwHnJHIJP9Q3qVDZe04l8BcXD1R6ezJ4Aqo7f9Ih9c2Ln7WeOu8NGiUrZUdnUYnLmuE0OuMtVXqx1ekXoHsHv079gD7XdYor3ihfJhWV5KrYHEonW51Rb1BTyKRO9Pi+QAAAAwGo2PPk+SsAAARA0lEQVQXRq8hVm492jueron32qdNpdC3MUPQMomKikpKSuJwOGgH0jHozHcvMt9rHAiD1fmaUlq9gsaA3ucn63Tg6KviFtw59vLyQjsEpMGd47y8PLRDQBrcOfb3f8skF+yBO8eZmZloh4A0uHNMXMfYh7iOsU/zXZBxAu4c19fXox0C0uDOMQ7BnWN/f39kVuGwHHDnODMzs9M9R3lPcOcYh+DOsZubG9ohIA3uHBcVFaEdAtLgzjEOwZ1jgUCAdghIgzvHtbW1aIeANLhzTCaTibYTxtHr9UQfCAHWwJ1ja2trtENAGtw5lkqlaIeANLhzjENw55gYe4t9iLG3BBgEd46JcZnYhxiXSYBBcOeYx+OhHQLS4M6xTCZDOwSkwZ1j4p4L+xD3XNjHxcUF7RCQBneOS0pK0A4BaXDnWCgUEmMEME55eTkx1gfj+Pn5teMsTIE7x1lZWWiHgDTvtc5eJyIoKMhgMJBIpKZ/KRRKXFzcggUL0A7N7ODlOvbw8ICrYRKJBP/r6uoaGxuLdlxIgBfHU6dOZTAYTS8pFMro0aNx0neNF8fR0dEikajppUgkGj9+PKoRIQdeHAMApk2bxmKx4KkSUVFR+Fn8BUeOx40b17VrV7g7c8KECWiHgxw4cgwAmDx5MpPJHD16NJfLRTsW5ECo7VT0tPFphkzRoK+r1iCQXRtodToKhYJuR5edM51Mgbz6cHyDkbjpQ8Lxw/S60nyluz/XxolBJbagAECvN0rKVRWFCjIZDJlgZ+7szO74ZoqkoVYXMtbBrLl0Uh6mSVSNupGx5v1xzHtVVRar6sVaQnBrBA63IVNJhVlys+ZiXsflBUoG+722rMA8XAG1JEdp1izM61jRoLd3YbTjRPxi68xQqwxmzcK8juV1Or3OrDl0eiAA6qvM29Yg7nKxD+EY+xCOsQ/hGPsQjrEP4Rj7EI6xD+EY+xCOsQ/hGPsQjrEP4Rj7WJbjvPycYSOCMjKumSS1Z9lZarW6nSenX/l7ZtyEyKhBBw4mIpAdkliWYxNyITV54aI4lapdj2aLigq+Wf9lT//AtWu+Dw+LNHd2CIPZB/gduqTuP7hNJpOX/fcLeKaMubNDGEt0nJZ+MfGXHysryz09u30yd3HPnoHwcZVKtXffz5fTLmg0ahdRl0mTZgwfNhIAUFJSvHXbt9nPs7hcXv9+A5cuSbh46ey2HzcCAKLHhwEAVn62ZtQHY1rL7tPl/3nw8C4AYER438GDhn+19vvq6qp9B3bevn2jsVHu4tJl2tRZYSNGNZ1/7vzpk6eSXr58weFwQwYM/nj2gtt3bjTPbt1XmwYNHIbIT9UuLNHxi6KCiROmyeUNJ04e/XTFf37cuqd7d3+DwfDlqv9WVpZPnzbLysr60aN7X3/zhUqljIwYt2nz1y9fvli44FOFovHho3skEqlf39BJH8YeO3742/Xb2GyOSOTaRnaz4ubzePzrN9LXrN5oY2MHANDpdc+fPx03diKfZ3X1etr6DaucnV18fXoAAA7+uvvX3/YMHRL24YTptXXSu3czKFTqa9m5unZF8Nd6O5boePas/wwYMAgAEB4WGTd74t59P2/ZnHj1WtqTzIdHjyTb2toBAMJGjFIqFSdOHo2MGFdZWe7t5RM1OgYAMOnDWACAQGAtFIoAAL6+fny+VdvZ+fn1un3nBgRBA0OHwkeETs4H9x+H5zlGRIyLmRB240a6r0+Pmprqw0f2h4dHfpGwDj5zyuSZrz7S7uyQxxIdN2FrazcwdNjfl8/rdLpbt67rdLppsWOb3tXr9Ww2B/5T+P3owZ+2fz8jdo5AYJqtBPILcg/+ujsn5xmckVQqgattvV4/bsxEk2SBGBbtGABgZ2ev1+tVKlVtrcTGxnbLD/9q2JApFADAnI8XCgTWh4/sP3/hzLy5i2OiJ71npg8e3l2ZEB8YEPTZijVsFnv12hUGowEAAJu2s+tkQ4kt3XFtrZTBYLDZbC6XV1dX6+DgRKfTXzsHgqCJE6ZFjBq3dduGn7Z/7+nh7e8fAL/1bjMEDh3aKxSKNqzfRqFQAABMBhM+zuFwAQDSWom9fcuaLXNRBotuH6tUqlu3rwcEBEEQ1Lt3X71efyb5z6Z3lcpXjVG43cJms+Pi5gMAcvOeN4kRi2veId96WZ2nhzcsWKPRKJQKg8EAAAgMCAIAnDv3V9OZOt2rYafvk525scTreO/+n6W1EoWi8UJqskxWH/fRJ3Clm5xyMnH3jxWV5d5ePvn5uddv/HNw/58MBmPtupUcNieoT/9bt68DALp5+wIAevj1IpPJO3b+EPHBWLVGPXZMByajBgQEpaYmnzt/msflHz9xpKFB9qKowGg0urh0iRodk5xyUiarDw4eUF9fl5x8YsuW3U6OwubZUWk0uFFnIZDXrl1rvtTzH8u51jSBA62d50ulksdPHgweNPzkqaSMjGtCoeiLhHXdff3gieFDh4TL5bL09EtXr6U1KuQRo8b5+weQSKTy8tJbt69fTrugVCnnzY0fOHAoAIDH5dnZOaSnX8rIuNbQIPvgg6g28n348O7Tp09mxM6BX/bo3qu4uPDkqaRHj+8NHRI+Pnpy2j+pXl4+Tk7O/fsNpNFoGRlX0/65WFb6Mjh4QGBAEJvNbp4dmUyGY2gPCpmuvEDRY4AZJ7ybd07bhV8rhR4cN3+O+bLo7IhLVfdSaz5cZsZVPC2xrDYHi5fOKSrKf/N4SMiQz1d+hUZEyIEXx6tXfavVad883nTPjGHw4hjuHcMnFt12IjAJhGPsQzjGPoRj7EM4xj6EY+xDOMY+hGPsQzjGPuZ1zGCTyFR8bcLSUSASYFuZt7fRvI7pTHJtteUOPLYE6mo0FJp5LZg3dXsXulapN2sWnR2FTOfk9vroJdNiXscePTn1Ys3L5+ZdD7LzUlutLnzS4B9q3uG6Zl/31mAwnvq5zM2f59GLSyIRdfP/U5LbeC9VPHWFi7nXe0ZojfIrJ6qzbsiEHkw92iW3Xq8nk8noxsDiUAqzGnyCuWFTkRjGi+geXuIytVpp3vU/38rSpUu//fZbJhPNoQEUOmTvTIeQKtUQHSNg62zem4v2UCPPcehK5XKxP/yjCaIPBPvgzjF+tnVqAneO6+vr0Q4BaXDn2NfXl9jjGuNkZ2db5swz84E7xx4eHmiHgDS4c1xQUIB2CEiDO8c4BHeOBQIB2iEgDe4c19bWoh0C0uDOsbe3N9ohIA3uHOfm5qIdAtLgzjEOwZ1jPz8/tENAGtw5zsrKQjsEpMGdYxyCO8deXl5oh4A0uHOcl5eHdghIgzvHOAR3jp2dndEOAWlw57isrAztEJAGd45xCO4c83g8tENAGtw5lslkaIeANLhzTIy9xT7E2FsCDII7x8T4auxDjK8mwCC4c+zp6Yl2CEiDO8f5+S3sOIBtcOeYeH6MfYjnx9iHTCYTbSeMo9fribYTAdYgHGMf3Dl2c3NDOwSkwZ3joqIitENAGkTX2UOR3r17v3Y7bTQao6OjV69ejV5QCIGX69jHxwf6NyKRKC4uDu24kAAvjiMjI1/b5H7gwIGurq7oRYQceHEcExPTtWvXppdCoXDatGmoRoQceHHMZrMjIiIolFdrwIaGhopEIrSDQgi8OAYAjB8/Hp4k4ezsPH36dLTDQQ4cOWaxWOPGjYMgaODAgfi5iC267SSv073Maayt0snrdRqlUaUwwQr2BqOh5GWJs7NzU6H9PrB5FIgMOHyytQPV2ZNpZUd7/zTNgSU6fnC59tmdBqVcbyXkAgBR6GQqgwyRLK/IMRo1Kp1OrQcA1Fc2UKmQTxAncJiAxrCsUC3L8d2LtbfPS5x8rFlWDCYP/UXrO4RKrlHUKqvyav1CrQaOtUZsK4G3YimOxRXaS0eqSFS6vZegsz/frSmsU9Yrhk60c/VmoB0LsBTH+Y/l/xwXu/cVkqko79hiKoxGY/H9ioAh3IDB5t27qT2g77isQJl2TOIS4IRuGOag7Gl10AhOt0AuumGg7Ljgifzm2TpMCoYpz67uEcTsherVjOYdoEyqTTtWg2HBAAChr/3jaw1lBQoUY0DT8cXD1W5BQhQDQAbX3sIrJyUGPWrlJWqOH12p1QMqhY7oJmJoQeeyrp8Ro5U7ao5vJkvt3PGyXLhNF6tntxpUjehsNomO44dX6uw9rEhky+oPgln3fdSfpzeaPFkHL+t7l+tMnmx7QOdXzr0vZ/Iton8AMdgCRu79BlSyRsGxSqGvrdKwBfhyTGNRIRIkKVcjnzUKtzwlOQo7N3N1C+QX3j93aWd5ZS6XY+3pFhQR/h8e1xYAsGr9iAljVmZlpz/LucFkcPoHx4wcNgf+iF6v/zt93617f2k0Sg/3Plqtykyx8Z04ZflKGyHS/fAoXMcyqU6nNUvKeQV39/y22MHebVL0l4NDphW+eJh4YKFG88pZ0smvhI7eCz5O7N0r4mLanmc5N+Djp1I2XUrf5+MdEhO1nEZlKFXmK1FJ0iqN2RJvFRSuY3mdzkz90n+d3dw/KCYmajn80tuz36afJufk3/LvPhQA0Lf32BFD4gAAQkfvO/dP5+bf6t4ttLT8+a17p0YMmRURNh8AEBQ4uqDogTliAwBQaOSGOnMVEm3li3yWaqWRaoZmsbS2oqqmSCwtuXXvr+bH6+qr4P/QaK/2tSaTyXyefb2sBgCQ+SwdADA4ZGrT+RBkrrKNwiCrG1HoCUHBsdFgNBhMv2N9g1wCAAgfNqdn92HNj3O5tm+eTCJRDAY9AKCurpLB4LBZSCzMZtQbdVrTf/G3goJjjhVZVmr63gAmgwsA0GrV9nZd23H6K9hsgUol1+o0VIrZR+po1Xo2H4UfHIV7Ljafotea3rGdrasV3/Hug2S1Rgkf0et1b727Ezn7AAAePkk1eTxvolPruQIUHKOQpbUjFTIqTZ4sBEHjIv/769GV23d/PKDveINBf+/huT4Bo5rXtW/Sq0fY3+n7T5zeWFlV6Ozk/aIkU9ZQY/LYYIx6na0zCr0CKFzHrt3YklKFQW/6msm/+9DZsVvIZOqZc1v/Tt8vEDi6dw1s+yNkMnnOjG3env0y7p5ISd1Ogkhslrme9UpL5V27s82UeBugM0YgZW+lnszkO3KQzxotGmtVDRW1Uz5FYVw3Oo/2uvfj3EtXANCq4+KSzD2/LX3zOJPBba2PIuqD+P5B0aaKMDvnxpE/W562amstEktL3zw+LnJZcODo1hJU1Cp7DEDnbxq1sT5HvisRdLFh8Vvu2NPqNA0NLTxwNRpBa4M2WUw+g2GyklCjUckbpa28CQHQwo/GZlnR6awWP6BV617cLZ+7Hp0lDFBzXJqnuHxc2iUQywN9mih7Wt17MNu3LzrbHKD2BFfkxRK60RrEjWgFgBhKmZrLA2gJRnk8V/hUe0lhrbrRPA8oLAOD3lB0t2LsPDSLK5RHYsz40rX4QQXqY7zNx4u7ZbGfo7xaAfpj6HVaQ+LKQo9+wk43walttCpdwa2yGV+6snkoj0tE3zHM4W9fchz4Vk4YaTHLqhur8yTTP3dlstGf3WMpjgEA1/4SP78nt/ew5jui0BlkKhrEiprCWldvRthUe7RjeYUFOQYAyCTaf/4UK+RGiErl2bFYVp1mzJeqQSOrbtQqNTSacehEWztnC6p3LMsxjKRCnf+kMf9RI0QiqRR6Co1MZVCB5c1XhciQtlGr0+joLIpOpXPvyfYOZNu7WNzfpSU6bkIh08nrdY0yvUquV6tQeLreNjQ6icEmsXkUNp/CsbLcCR8W7ZjAJFjiTAUC00I4xj6EY+xDOMY+hGPsQzjGPv8LRD/qBICa74YAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# Construct the graph: here we put everything together to construct our graph\n",
    "graph = StateGraph(OverallState)\n",
    "graph.add_node(\"generate_topics\", generate_topics)\n",
    "graph.add_node(\"generate_fact\", generate_fact)\n",
    "graph.add_node(\"best_fact\", best_fact)\n",
    "graph.add_edge(START, \"generate_topics\")\n",
    "graph.add_conditional_edges(\"generate_topics\", continue_to_facts, [\"generate_fact\"])\n",
    "graph.add_edge(\"generate_fact\", \"best_fact\")\n",
    "graph.add_edge(\"best_fact\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = graph.compile()\n",
    "Image(app.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e21dc7c9-0add-4125-be76-af701adb874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects=['Technology']\n",
      "{'generate_topics': {'subjects': ['Technology']}}\n",
      "Technology\n",
      "{'generate_fact': {'facts': [\"The first computer virus, called 'Creeper,' was created in 1971 as an experimental self-replicating program. It displayed the message 'I'm the creeper, catch me if you can!' and was not designed to cause harm.\"]}}\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 85097 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 85097 seconds before retrying.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Call the graph: here we call it to generate a list of jokes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtopic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtechnology\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1656\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1652\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1656\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1658\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1659\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1660\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1661\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   1663\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/langgraph/pregel/runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/langgraph/utils/runnable.py:408\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    405\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    406\u001b[0m )\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/langgraph/utils/runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[73], line 4\u001b[0m, in \u001b[0;36mbest_fact\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      2\u001b[0m facts \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacts\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m best_fact_prompt\u001b[38;5;241m.\u001b[39mformat(topic\u001b[38;5;241m=\u001b[39mstate[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m], facts\u001b[38;5;241m=\u001b[39mfacts)\n\u001b[0;32m----> 4\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBestFact\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_selected_fact\u001b[39m\u001b[38;5;124m\"\u001b[39m: state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacts\u001b[39m\u001b[38;5;124m\"\u001b[39m][response\u001b[38;5;241m.\u001b[39mid]}\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/langchain_core/runnables/base.py:3022\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m   3021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3023\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3024\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/langchain_core/runnables/base.py:5354\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5350\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5351\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5352\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5356\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    285\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 286\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    647\u001b[0m ]\n\u001b[1;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 633\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m         )\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:705\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/openai/_utils/_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/openai/resources/chat/completions.py:815\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    813\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    814\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 815\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/openai/_base_client.py:1277\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1265\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1274\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1275\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1276\u001b[0m     )\n\u001b[0;32m-> 1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/openai/_base_client.py:954\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 954\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/openai/_base_client.py:1043\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1042\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/openai/_base_client.py:1092\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/openai/_base_client.py:1043\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1042\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/openai/_base_client.py:1092\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/openai/_base_client.py:1058\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1057\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1061\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1062\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1067\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 85097 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 85097 seconds before retrying.'}}",
      "\u001b[0mDuring task with name 'best_fact' and id '80ea16cf-2202-651e-929c-10bdbf5ef40e'"
     ]
    }
   ],
   "source": [
    "# Call the graph: here we call it to generate a list of jokes\n",
    "for s in app.stream({\"topic\": \"technology\"}):\n",
    "    print(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a96517e-77ab-46e2-95e2-79168c044e9c",
   "metadata": {},
   "source": [
    "## Studio\n",
    "\n",
    "--\n",
    "\n",
    "** DISCLAIMER**\n",
    "\n",
    "*Running Studio currently requires a Mac. If you are not using a Mac, then skip this step.*\n",
    "\n",
    "*Also, if you are running this notebook in CoLab, then skip this step.*\n",
    "\n",
    "--\n",
    "\n",
    "Let's load our the above graph in the Studio UI, which uses `module-4/studio/map_reduce.py` set in `module-4/studio/langgraph.json`.\n",
    "\n",
    "![Screenshot 2024-08-28 at 3.17.53 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbb0c0ed88a12e822811e2_map-reduce1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a5e45-9a4c-43b4-8393-9298b3dcda53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
